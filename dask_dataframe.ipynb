{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsAiJR-JkQ7s"
      },
      "source": [
        "# Dask Dataframe\n",
        "\n",
        "- Distributed pandas-like dataframes, for efficient handling of tabular, organized data\n",
        "- Scales well for large data sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YsJVy4QkQ7y"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/dmbala/python-bigData/main/Figures/dask-dataframe.png\" width=500 height=400>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzyvn9OnkQ7z"
      },
      "outputs": [],
      "source": [
        "# Importing dask dataframe\n",
        "import dask\n",
        "import dask.dataframe as dd\n",
        "dask.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install memory_profiler"
      ],
      "metadata": {
        "id": "9pO1t_bIkYQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbCzFMjckQ72"
      },
      "outputs": [],
      "source": [
        "# Importing pandas, numpy, sys, gc, and time \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import time\n",
        "import sys\n",
        "%load_ext memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data=np.random.randint(99999, 99999999, size=(1000000,14)),columns=['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14'])\n",
        "df['C15'] = pd.util.testing.rands_array(5, 1000000)\n",
        "# Store data in CSV format\n",
        "df.to_csv(\"huge_data.csv\")"
      ],
      "metadata": {
        "id": "WfUbauPllFg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df"
      ],
      "metadata": {
        "id": "G9P0idUJmUBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAwpUAjxkQ73"
      },
      "outputs": [],
      "source": [
        "# Get the file size\n",
        "import os\n",
        "file = os.path.getsize(\"huge_data.csv\")\n",
        "print ('File size  {}'.format(file/1024/1024/1024), \"GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFBhmZhUkQ74"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Measure time and memory to read the data from csv into pandas dataframe\n",
        "p_df = pd.read_csv('huge_data.csv')\n",
        "%memit p_df = pd.read_csv('huge_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxchD2aVkQ74"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Measure time and memory to read the data from csv into pandas dataframe\n",
        "%memit d_df = dd.read_csv('huge_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIkQ99ZxkQ75"
      },
      "outputs": [],
      "source": [
        "print(\"Mem used by dask dataframe \", sys.getsizeof(d_df)/(1024*1024*1024), \"GB\")\n",
        "print(\"Mem used by pandas dataframe \", sys.getsizeof(p_df)/(1024*1024*1024), \"GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9oHzYlekQ77"
      },
      "outputs": [],
      "source": [
        "d_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVhkO66rkQ7_"
      },
      "outputs": [],
      "source": [
        "#%%time\n",
        "#pandasFile_tmp = pd.read_csv('huge_data.csv')\n",
        "#for i in range(3):\n",
        "#    pandasFile = pandasFile.append(pandasFile_tmp)\n",
        "#pandasFile.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%memit p_df_tmp = pd.read_csv('huge_data.csv')\n",
        "%memit p_df_final = p_df.append(p_df_tmp)"
      ],
      "metadata": {
        "id": "opBXj0kEnXxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del p_df\n",
        "del p_df_tmp\n",
        "del p_df_final"
      ],
      "metadata": {
        "id": "pxt0ag5Zn-y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39WSngigkQ8A"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%memit d_df_tmp = dd.read_csv('huge_data.csv')\n",
        "%memit d_df_final = d_df.append(d_df_tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHTUIWlakQ8B"
      },
      "outputs": [],
      "source": [
        "%memit print( \"rows = \", len(d_df), \"Columns = \", len(d_df.columns)) \n",
        "%memit print( \"rows = \", len(d_df_final), \"Columns = \", len(d_df_final.columns))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVAYEtSUkQ8B"
      },
      "source": [
        "## Summary\n",
        "- In comparison to pandas dataframe, Dask dataframe is more efficient in terms of speed and memory"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}