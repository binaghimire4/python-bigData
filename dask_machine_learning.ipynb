{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grsIrrZ9RoU-"
      },
      "source": [
        "# Dask Machine Learning\n",
        "\n",
        "- Dask-ML enables scalable machine learning\n",
        "- It comes with explicit support for certain models such as dask-xgboost\n",
        "- It supports existing machine learning methods such as scikit-learn, tensorflow, keras, etc. \n",
        "- Large Model (Exploit parallelism with delayed executions, Hyperparameter tunning, etc.,)\n",
        "- Large Data (Dask Collections to manage memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7bACPCvRoVF"
      },
      "source": [
        "#### CPU bound vs MEM bound Machine Learning Models\n",
        "<img src=\"https://raw.githubusercontent.com/dmbala/python-bigData/main/Figures/cpu_mem_bound.png\" width=500 height=400>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-smXIoMRoVF"
      },
      "source": [
        "#### Distributed Machine Learning across multiple nodes\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/dmbala/python-bigData/main/Figures/DaskDistributedJob.png\" width=500 height=200>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3w764SSRoVG"
      },
      "source": [
        "### Compute Bound\n",
        "\n",
        "- Distribute training and prediction across multiple nodes. \n",
        "- Hyperparameter tunning\n",
        "\n",
        "### Memory Bound \n",
        "- Blockwise Ensemble Methods\n",
        "- Incremental Learning\n",
        "\n",
        "### Compute and Memory Bound\n",
        "Re-implemented Models like dask-xgboost and dask-knn are efficeint with both CPU and Memor intensive computations. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgUFqD5JRoVH",
        "outputId": "e0bfa0df-ed31-453d-8a95-a547e3f031be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.30.0'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing dask \n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import dask.delayed as delayed\n",
        "import dask_ml.datasets\n",
        "import dask_ml.cluster\n",
        "import time\n",
        "%load_ext memory_profiler\n",
        "dask.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install memory_profiler"
      ],
      "metadata": {
        "id": "7A8-iihfRycc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erlm3NndRoVJ"
      },
      "source": [
        "## Blockwise Ensemble Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPuTE_39RoVK"
      },
      "source": [
        "- Ensemble methods such as Bagging methods, Forrests of randomized trees, etc., are good for blockwise approaches. \n",
        "- Create homogenous data blocks from dask.array or dask.dataframe. \n",
        "- Train a copy of the model on each block. \n",
        "- At prediction, take an ensemble average of the trainined models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT-X6xHiRoVL",
        "outputId": "36a01dbf-6d96-454d-a1e2-73715e1bdfae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table>\n",
              "<tr>\n",
              "<td>\n",
              "<table>\n",
              "  <thead>\n",
              "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr><th> Bytes </th><td> 1.60 MB </td> <td> 160.00 kB </td></tr>\n",
              "    <tr><th> Shape </th><td> (10000, 20) </td> <td> (1000, 20) </td></tr>\n",
              "    <tr><th> Count </th><td> 10 Tasks </td><td> 10 Chunks </td></tr>\n",
              "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td>\n",
              "<td>\n",
              "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
              "\n",
              "  <!-- Horizontal lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
              "  <line x1=\"0\" y1=\"24\" x2=\"25\" y2=\"24\" />\n",
              "  <line x1=\"0\" y1=\"36\" x2=\"25\" y2=\"36\" />\n",
              "  <line x1=\"0\" y1=\"48\" x2=\"25\" y2=\"48\" />\n",
              "  <line x1=\"0\" y1=\"60\" x2=\"25\" y2=\"60\" />\n",
              "  <line x1=\"0\" y1=\"72\" x2=\"25\" y2=\"72\" />\n",
              "  <line x1=\"0\" y1=\"84\" x2=\"25\" y2=\"84\" />\n",
              "  <line x1=\"0\" y1=\"96\" x2=\"25\" y2=\"96\" />\n",
              "  <line x1=\"0\" y1=\"108\" x2=\"25\" y2=\"108\" />\n",
              "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Vertical lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Colored Rectangle -->\n",
              "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
              "\n",
              "  <!-- Text -->\n",
              "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >20</text>\n",
              "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">10000</text>\n",
              "</svg>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "dask.array<normal, shape=(10000, 20), dtype=float64, chunksize=(1000, 20), chunktype=numpy.ndarray>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# A classification example from dask_ml.datasets\n",
        "X, y = dask_ml.datasets.make_classification(n_samples=1e4, chunks=1e3, random_state=0)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9iwl6QhRoVM"
      },
      "source": [
        "The sub-estimator should be an instantiated scikit-learn-API compatible estimator (anything that implements the fit / predict API, including pipelines). It only needs to handle in-memory datasets. We’ll use sklearn.linear_model.RandomForestClassifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ousm1U1bRoVN",
        "outputId": "b1b8aad5-826c-497e-e185-30705f5cd747"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BlockwiseVotingClassifier(classes=[0, 1],\n",
              "                          estimator=RandomForestClassifier(random_state=0))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import dask_ml.ensemble\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "subestimator = RandomForestClassifier(random_state=0)\n",
        "clf = dask_ml.ensemble.BlockwiseVotingClassifier(\n",
        "    subestimator,\n",
        "    classes=[0, 1]\n",
        ")\n",
        "clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWliZc9kRoVO"
      },
      "source": [
        "We can train the esemble of models on data chunks. This will independently fit a clone of subestimator on each partition of X and y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXyzR8ERRoVP"
      },
      "outputs": [],
      "source": [
        "clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwCpVpjHRoVQ",
        "outputId": "2132b4be-4962-4330-a633-85e77951e54e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[RandomForestClassifier(random_state=0),\n",
              " RandomForestClassifier(random_state=0),\n",
              " RandomForestClassifier(random_state=0),\n",
              " RandomForestClassifier(random_state=0),\n",
              " RandomForestClassifier(random_state=0),\n",
              " RandomForestClassifier(random_state=0),\n",
              " RandomForestClassifier(random_state=0),\n",
              " RandomForestClassifier(random_state=0),\n",
              " RandomForestClassifier(random_state=0),\n",
              " RandomForestClassifier(random_state=0)]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.estimators_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtGpiEsgRoVS"
      },
      "source": [
        "Different estimators were trained on separate batches of data. Each estimator has its own set of parameters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmrFT_xdRoVS",
        "outputId": "d0cda81f-a74d-419c-b0d4-b15f26e6ca25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds = clf.predict(X[:20])\n",
        "preds.compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw0Dl4bjRoVT"
      },
      "source": [
        "The prediction calls subestimator.predict(chunk) for each subestimator (20 in our case). These subestimator predictions are averaged at the end. \n",
        "\n",
        "The blockwise algorithm was applied to the training and the prediction steps. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAMZNhIoRoVT",
        "outputId": "5f676ba1-762e-47fb-acd5-9398b173cc2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "peak memory: 227.35 MiB, increment: 4.62 MiB\n",
            "CPU times: user 7.5 s, sys: 1.35 s, total: 8.85 s\n",
            "Wall time: 4.75 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%memit clf.score(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-u4b3IxRoVV"
      },
      "source": [
        "### Predictions on large data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awMAcUeoRoVV",
        "outputId": "30335b93-612c-4b44-a2fb-b75f9deaa1c7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table>\n",
              "<tr>\n",
              "<td>\n",
              "<table>\n",
              "  <thead>\n",
              "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr><th> Bytes </th><td> 16.00 MB </td> <td> 160.00 kB </td></tr>\n",
              "    <tr><th> Shape </th><td> (100000, 20) </td> <td> (1000, 20) </td></tr>\n",
              "    <tr><th> Count </th><td> 110 Tasks </td><td> 100 Chunks </td></tr>\n",
              "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td>\n",
              "<td>\n",
              "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
              "\n",
              "  <!-- Horizontal lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"0\" y1=\"6\" x2=\"25\" y2=\"6\" />\n",
              "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
              "  <line x1=\"0\" y1=\"18\" x2=\"25\" y2=\"18\" />\n",
              "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" />\n",
              "  <line x1=\"0\" y1=\"31\" x2=\"25\" y2=\"31\" />\n",
              "  <line x1=\"0\" y1=\"37\" x2=\"25\" y2=\"37\" />\n",
              "  <line x1=\"0\" y1=\"43\" x2=\"25\" y2=\"43\" />\n",
              "  <line x1=\"0\" y1=\"50\" x2=\"25\" y2=\"50\" />\n",
              "  <line x1=\"0\" y1=\"56\" x2=\"25\" y2=\"56\" />\n",
              "  <line x1=\"0\" y1=\"62\" x2=\"25\" y2=\"62\" />\n",
              "  <line x1=\"0\" y1=\"68\" x2=\"25\" y2=\"68\" />\n",
              "  <line x1=\"0\" y1=\"75\" x2=\"25\" y2=\"75\" />\n",
              "  <line x1=\"0\" y1=\"81\" x2=\"25\" y2=\"81\" />\n",
              "  <line x1=\"0\" y1=\"87\" x2=\"25\" y2=\"87\" />\n",
              "  <line x1=\"0\" y1=\"93\" x2=\"25\" y2=\"93\" />\n",
              "  <line x1=\"0\" y1=\"100\" x2=\"25\" y2=\"100\" />\n",
              "  <line x1=\"0\" y1=\"106\" x2=\"25\" y2=\"106\" />\n",
              "  <line x1=\"0\" y1=\"112\" x2=\"25\" y2=\"112\" />\n",
              "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Vertical lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Colored Rectangle -->\n",
              "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
              "\n",
              "  <!-- Text -->\n",
              "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >20</text>\n",
              "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">100000</text>\n",
              "</svg>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "dask.array<concatenate, shape=(100000, 20), dtype=float64, chunksize=(1000, 20), chunktype=numpy.ndarray>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#da.concatenate([X, X, X, X])\n",
        "N = 10\n",
        "X_large = da.concatenate([ X for _ in range(N)])\n",
        "y_large = da.concatenate([ y for _ in range(N)])\n",
        "X_large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C9rXujPRoVY",
        "outputId": "3eae19fd-d01e-48a2-9520-f6a3ace7322c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table>\n",
              "<tr>\n",
              "<td>\n",
              "<table>\n",
              "  <thead>\n",
              "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr><th> Bytes </th><td> 16.00 MB </td> <td> 1.60 MB </td></tr>\n",
              "    <tr><th> Shape </th><td> (100000, 20) </td> <td> (10000, 20) </td></tr>\n",
              "    <tr><th> Count </th><td> 120 Tasks </td><td> 10 Chunks </td></tr>\n",
              "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td>\n",
              "<td>\n",
              "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
              "\n",
              "  <!-- Horizontal lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
              "  <line x1=\"0\" y1=\"24\" x2=\"25\" y2=\"24\" />\n",
              "  <line x1=\"0\" y1=\"36\" x2=\"25\" y2=\"36\" />\n",
              "  <line x1=\"0\" y1=\"48\" x2=\"25\" y2=\"48\" />\n",
              "  <line x1=\"0\" y1=\"60\" x2=\"25\" y2=\"60\" />\n",
              "  <line x1=\"0\" y1=\"72\" x2=\"25\" y2=\"72\" />\n",
              "  <line x1=\"0\" y1=\"84\" x2=\"25\" y2=\"84\" />\n",
              "  <line x1=\"0\" y1=\"96\" x2=\"25\" y2=\"96\" />\n",
              "  <line x1=\"0\" y1=\"108\" x2=\"25\" y2=\"108\" />\n",
              "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Vertical lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Colored Rectangle -->\n",
              "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
              "\n",
              "  <!-- Text -->\n",
              "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >20</text>\n",
              "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">100000</text>\n",
              "</svg>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "dask.array<rechunk-merge, shape=(100000, 20), dtype=float64, chunksize=(10000, 20), chunktype=numpy.ndarray>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_large.rechunk(10000, 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk5n6BfARoVa",
        "outputId": "63d88a5c-76f6-46cd-ddf0-7ceae40c29cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table>\n",
              "<tr>\n",
              "<td>\n",
              "<table>\n",
              "  <thead>\n",
              "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr><th> Bytes </th><td> 800.00 kB </td> <td> 80.00 kB </td></tr>\n",
              "    <tr><th> Shape </th><td> (100000,) </td> <td> (10000,) </td></tr>\n",
              "    <tr><th> Count </th><td> 231 Tasks </td><td> 10 Chunks </td></tr>\n",
              "    <tr><th> Type </th><td> int64 </td><td> numpy.ndarray </td></tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td>\n",
              "<td>\n",
              "<svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
              "\n",
              "  <!-- Horizontal lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Vertical lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"25\" />\n",
              "  <line x1=\"24\" y1=\"0\" x2=\"24\" y2=\"25\" />\n",
              "  <line x1=\"36\" y1=\"0\" x2=\"36\" y2=\"25\" />\n",
              "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"25\" />\n",
              "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
              "  <line x1=\"72\" y1=\"0\" x2=\"72\" y2=\"25\" />\n",
              "  <line x1=\"84\" y1=\"0\" x2=\"84\" y2=\"25\" />\n",
              "  <line x1=\"96\" y1=\"0\" x2=\"96\" y2=\"25\" />\n",
              "  <line x1=\"108\" y1=\"0\" x2=\"108\" y2=\"25\" />\n",
              "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Colored Rectangle -->\n",
              "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
              "\n",
              "  <!-- Text -->\n",
              "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >100000</text>\n",
              "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
              "</svg>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "dask.array<rechunk-merge, shape=(100000,), dtype=int64, chunksize=(10000,), chunktype=numpy.ndarray>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_large.rechunk(10000, 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ole2tTzjRoVc",
        "outputId": "d13f64a6-f26a-4e99-f002-d9b66906dabb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6703"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(X_large, y_large)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3_2KHavRoVd",
        "outputId": "06cfbebd-c8b3-422c-aa7f-b16bdc24b7c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "peak memory: 234.38 MiB, increment: 0.48 MiB\n",
            "CPU times: user 7.72 s, sys: 1.31 s, total: 9.03 s\n",
            "Wall time: 4.98 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%memit clf.score(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCozpi4yRoVe",
        "outputId": "da8b9081-3e0c-47b7-d408-f65ef43854bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "peak memory: 235.88 MiB, increment: 1.50 MiB\n",
            "CPU times: user 1min 48s, sys: 23.3 s, total: 2min 11s\n",
            "Wall time: 1min 10s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%memit clf.score(X_large, y_large)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpOlY1m4RoVe"
      },
      "source": [
        "## Incremental learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJSIwF22RoVe"
      },
      "source": [
        "- Some estimators are suitable for incremental training. This is useful for on-line training and as well training of large data sets. \n",
        "\n",
        "- Scikit-Learn provides partial_fit function for incremental learning. The partial_fit function works with Stochastic Gradient Descent, K-means, and Passive-Aggresive, and Naive Bayes based ML methods. \n",
        "\n",
        "- dask_ml.wrappers.Incremental acts as a bridge between Dask and Scikit-Learn estimators supporting the partial_fit API. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwRJJ2DNRoVf"
      },
      "outputs": [],
      "source": [
        "from dask_ml.wrappers import Incremental\n",
        "from sklearn.linear_model import SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBiC6Ja_RoVf",
        "outputId": "9708e085-40c0-48c1-f939-7bcb2b69d6be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table>\n",
              "<tr>\n",
              "<td>\n",
              "<table>\n",
              "  <thead>\n",
              "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr><th> Bytes </th><td> 1.60 MB </td> <td> 160.00 kB </td></tr>\n",
              "    <tr><th> Shape </th><td> (10000, 20) </td> <td> (1000, 20) </td></tr>\n",
              "    <tr><th> Count </th><td> 10 Tasks </td><td> 10 Chunks </td></tr>\n",
              "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td>\n",
              "<td>\n",
              "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
              "\n",
              "  <!-- Horizontal lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
              "  <line x1=\"0\" y1=\"24\" x2=\"25\" y2=\"24\" />\n",
              "  <line x1=\"0\" y1=\"36\" x2=\"25\" y2=\"36\" />\n",
              "  <line x1=\"0\" y1=\"48\" x2=\"25\" y2=\"48\" />\n",
              "  <line x1=\"0\" y1=\"60\" x2=\"25\" y2=\"60\" />\n",
              "  <line x1=\"0\" y1=\"72\" x2=\"25\" y2=\"72\" />\n",
              "  <line x1=\"0\" y1=\"84\" x2=\"25\" y2=\"84\" />\n",
              "  <line x1=\"0\" y1=\"96\" x2=\"25\" y2=\"96\" />\n",
              "  <line x1=\"0\" y1=\"108\" x2=\"25\" y2=\"108\" />\n",
              "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Vertical lines -->\n",
              "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
              "\n",
              "  <!-- Colored Rectangle -->\n",
              "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
              "\n",
              "  <!-- Text -->\n",
              "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >20</text>\n",
              "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">10000</text>\n",
              "</svg>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "dask.array<normal, shape=(10000, 20), dtype=float64, chunksize=(1000, 20), chunktype=numpy.ndarray>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y = dask_ml.datasets.make_classification(n_samples=10000, chunks=1000, random_state=0)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCQ_jMN5RoVg",
        "outputId": "70e7b616-bed6-4829-8bdf-3f6dbbb56eaa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Incremental(estimator=SGDClassifier(max_iter=100, random_state=10))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "estimator = SGDClassifier(random_state=10, max_iter=100)\n",
        "clf = Incremental(estimator)\n",
        "clf.fit(X, y, classes=[0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv_vzArXRoVg"
      },
      "source": [
        "As usual with Dask-ML, scoring is done in parallel (and distributed on a cluster if you’re connected to one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y5RkrDGRoVg",
        "outputId": "21a0c41a-3295-4742-836b-b916b42e67e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5701"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.score(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htH48JekRoVh"
      },
      "source": [
        "## Hyper parameter Search -  Support Vector Classifier (CPU Bound)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/dmbala/python-bigData/main/Figures/svc.png\" width=500 height=400>\n",
        "\n",
        " https://www.datacamp.com/tutorial/svm-classification-scikit-learn-python"
      ],
      "metadata": {
        "id": "H0X5-oSvUhNB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3RXgCoJRoVi"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import pandas as pd\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHVTsv8QRoVj",
        "outputId": "af5049d1-51d9-42ed-ebc0-f1c0bdd98420"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"border: 2px solid white;\">\n",
              "<tr>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Client</h3>\n",
              "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
              "  <li><b>Scheduler: </b>tcp://127.0.0.1:46003</li>\n",
              "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
              "</ul>\n",
              "</td>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Cluster</h3>\n",
              "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
              "  <li><b>Workers: </b>8</li>\n",
              "  <li><b>Cores: </b>64</li>\n",
              "  <li><b>Memory: </b>32.00 GB</li>\n",
              "</ul>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<Client: 'tcp://127.0.0.1:46003' processes=8 threads=64, memory=32.00 GB>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dask.distributed import Client, LocalCluster\n",
        "client = Client(n_workers=8, threads_per_worker=8, memory_limit='4GB')\n",
        "client "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co0qlpgGRoVj",
        "outputId": "8158a3f4-436c-4358-922a-1bc10ff079fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1.06377997,  0.67640868,  1.06935647, -0.21758002,  0.46021477,\n",
              "        -0.39916689, -0.07918751,  1.20938491, -0.78531472, -0.17218611,\n",
              "        -1.08535744, -0.99311895,  0.30693511,  0.06405769, -1.0542328 ,\n",
              "        -0.52749607, -0.0741832 , -0.35562842,  1.05721416, -0.90259159],\n",
              "       [ 0.0708476 , -1.69528125,  2.44944917, -0.5304942 , -0.93296221,\n",
              "         2.86520354,  2.43572851, -1.61850016,  1.30071691,  0.34840246,\n",
              "         0.54493439,  0.22532411,  0.60556322, -0.19210097, -0.06802699,\n",
              "         0.9716812 , -1.79204799,  0.01708348, -0.37566904, -0.62323644]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y = make_classification(n_samples=1000, random_state=0)\n",
        "X[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiMGBwWLRoVk"
      },
      "outputs": [],
      "source": [
        "param_grid = {\"C\": [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
        "              \"kernel\": ['rbf', 'poly', 'sigmoid'],\n",
        "              \"shrinking\": [True, False]}\n",
        "\n",
        "grid_search = GridSearchCV(SVC(gamma='auto', random_state=0, probability=True),\n",
        "                           param_grid=param_grid,\n",
        "                           return_train_score=False,\n",
        "                           iid=True, n_jobs=-1,\n",
        "                           cv=3)\n",
        "                           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnQicxuFRoVl",
        "outputId": "0045f27d-8593-4e0a-b6c0-5f6ccd938244"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 510 ms, sys: 625 ms, total: 1.13 s\n",
            "Wall time: 3.32 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/projects/community/py-bigdata/2020/bd387/envs/dask-ml/lib/python3.8/site-packages/sklearn/model_selection/_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=SVC(gamma='auto', probability=True, random_state=0),\n",
              "             iid=True, n_jobs=-1,\n",
              "             param_grid={'C': [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0],\n",
              "                         'kernel': ['rbf', 'poly', 'sigmoid'],\n",
              "                         'shrinking': [True, False]})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "grid_search.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFc2KVdXRoVm"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "with joblib.parallel_backend('dask'):\n",
        "    grid_search.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0vV04w-RoVm",
        "outputId": "9dd2135d-8e2c-487d-b09f-9ec65556edac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.972"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.score(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by8kVeIeRoVm"
      },
      "outputs": [],
      "source": [
        "client.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sYF4K8PRoVn"
      },
      "source": [
        "## Summary\n",
        "- Deploy dask-ml and dask collections to manage large data for the machine learning\n",
        "- Hyperparameter training of models can be accomplished by distributing the jobs on multiple machines"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}